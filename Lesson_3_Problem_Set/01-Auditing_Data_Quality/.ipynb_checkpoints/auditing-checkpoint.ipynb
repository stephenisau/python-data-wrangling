{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aed9268488c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-aed9268488c5>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mfieldtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudit_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCITIES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIELDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfieldtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aed9268488c5>\u001b[0m in \u001b[0;36maudit_file\u001b[0;34m(filename, fields)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NULL\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mfieldtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32melif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'{'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                     \u001b[0mfieldtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "In this problem set you work with cities infobox data, audit it, come up with a\n",
    "cleaning idea and then clean it up. In the first exercise we want you to audit\n",
    "the datatypes that can be found in some particular fields in the dataset.\n",
    "The possible types of values can be:\n",
    "- NoneType if the value is a string \"NULL\" or an empty string \"\"\n",
    "- list, if the value starts with \"{\"\n",
    "- int, if the value can be cast to int\n",
    "- float, if the value can be cast to float, but CANNOT be cast to int.\n",
    "   For example, '3.23e+07' should be considered a float because it can be cast\n",
    "   as float but int('3.23e+07') will throw a ValueError\n",
    "- 'str', for all other values\n",
    "\n",
    "The audit_file function should return a dictionary containing fieldnames and a \n",
    "SET of the types that can be found in the field. e.g.\n",
    "{\"field1\": set([type(float()), type(int()), type(str())]),\n",
    " \"field2\": set([type(str())]),\n",
    "  ....\n",
    "}\n",
    "The type() function returns a type object describing the argument given to the \n",
    "function. You can also use examples of objects to create type objects, e.g.\n",
    "type(1.1) for a float: see the test function below for examples.\n",
    "\n",
    "Note that the first three rows (after the header row) in the cities.csv file\n",
    "are not actual data points. The contents of these rows should note be included\n",
    "when processing data types. Be sure to include functionality in your code to\n",
    "skip over or detect these rows.\n",
    "\"\"\"\n",
    "\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "FIELDS = [\"name\", \"timeZone_label\", \"utcOffset\", \"homepage\", \"governmentType_label\",\n",
    "          \"isPartOf_label\", \"areaCode\", \"populationTotal\", \"elevation\",\n",
    "          \"maximumElevation\", \"minimumElevation\", \"populationDensity\",\n",
    "          \"wgs84_pos#lat\", \"wgs84_pos#long\", \"areaLand\", \"areaMetro\", \"areaUrban\"]\n",
    "\n",
    "\n",
    "def isfloat(value):#create a function that tests whether a value can be cast as float\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def isint(value):#create a function that determines if a value is an integer\n",
    "    try:\n",
    "        int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def audit_file(filename, fields):\n",
    "    fieldtypes = {}\n",
    "    for i in fields:\n",
    "        fieldtypes[i] = set()#make each field value a set\n",
    "    with open(filename,'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for i in range(3):\n",
    "            reader.next()#skips first 3 rows\n",
    "        for row in reader:\n",
    "            for field in fields:\n",
    "                value = row[field]#match row and column values\n",
    "                if value == 'NULL' or value == '':\n",
    "                    fieldtypes[field].append(type(None))\n",
    "                elif value.startswith('{'):\n",
    "                    fieldtypes[field].add(type(None))\n",
    "                else:\n",
    "                    try:\n",
    "                        int(value)\n",
    "                        fieldtypes[field].add(int)\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            float(value)\n",
    "                            fieldtypes[field].add(float)\n",
    "                        except ValueError:\n",
    "                            fieldtypes[field].add(str)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    return fieldtypes\n",
    "\n",
    "\n",
    "def test():\n",
    "    fieldtypes = audit_file(CITIES, FIELDS)\n",
    "\n",
    "    pprint.pprint(fieldtypes)\n",
    "\n",
    "    assert fieldtypes[\"areaLand\"] == set([type(1.1), type([]), type(None)])\n",
    "    assert fieldtypes['areaMetro'] == set([type(1.1), type(None)])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everythiing below this is notes to test out code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': [], 'timeZone_label': [], 'utcOffset': [], 'homepage': [], 'governmentType_label': [], 'isPartOf_label': [], 'areaCode': [], 'populationTotal': [], 'elevation': [], 'maximumElevation': [], 'minimumElevation': [], 'populationDensity': [], 'wgs84_pos#lat': [], 'wgs84_pos#long': [], 'areaLand': [], 'areaMetro': [], 'areaUrban': []}\n"
     ]
    }
   ],
   "source": [
    "fieldtypes = {}\n",
    "for i in FIELDS:\n",
    "    fieldtypes[i] = []\n",
    "print(fieldtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_file(filename, fields):\n",
    "    fieldtypes = {}\n",
    "    for i in FIELDS:\n",
    "        fieldtypes[i] = []\n",
    "    with open(filename,'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        for field in FIELDS:\n",
    "            for row in reader:\n",
    "                if row[field] == \"NULL\" or row[field] == \"\":\n",
    "                    fieldtypes[field].append(type(None))\n",
    "                elif row[field[0]] == '{':\n",
    "                    fieldtypes[field].append(type([]))\n",
    "                elif isint(row[field]):\n",
    "                    fieldtypes[field].append(type(1.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['URI', 'rdf-schema#label', 'rdf-schema#comment', 'administrativeDistrict_label', 'administrativeDistrict', 'anthem_label', 'anthem', 'area', 'areaCode', 'areaLand', 'areaMetro', 'areaRural', 'areaTotal', 'areaUrban', 'areaWater', 'city_label', 'city', 'code', 'country_label', 'country', 'daylightSavingTimeZone_label', 'daylightSavingTimeZone', 'district_label', 'district', 'division_label', 'division', 'elevation', 'federalState_label', 'federalState', 'foundingDate', 'foundingPerson_label', 'foundingPerson', 'foundingYear', 'governingBody_label', 'governingBody', 'government_label', 'government', 'governmentType_label', 'governmentType', 'isPartOf_label', 'isPartOf', 'isoCodeRegion_label', 'isoCodeRegion', 'leader_label', 'leader', 'leaderName_label', 'leaderName', 'leaderParty_label', 'leaderParty', 'leaderTitle', 'location_label', 'location', 'maximumElevation', 'mayor_label', 'mayor', 'minimumElevation', 'motto', 'municipality_label', 'municipality', 'part_label', 'part', 'percentageOfAreaWater', 'populationAsOf', 'populationDensity', 'populationMetro', 'populationMetroDensity', 'populationRural', 'populationTotal', 'populationTotalRanking', 'populationUrban', 'populationUrbanDensity', 'postalCode', 'region_label', 'region', 'state_label', 'state', 'synonym', 'thumbnail_label', 'thumbnail', 'timeZone_label', 'timeZone', 'twinCity_label', 'twinCity', 'twinCountry_label', 'twinCountry', 'type_label', 'type', 'utcOffset', 'point', '22-rdf-syntax-ns#type_label', '22-rdf-syntax-ns#type', 'wgs84_pos#lat', 'wgs84_pos#long', 'depiction_label', 'depiction', 'homepage_label', 'homepage', 'name', 'nick']\n"
     ]
    }
   ],
   "source": [
    "with open(CITIES, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    header = reader.fieldnames\n",
    "    for field in FIELDS:\n",
    "        for row in reader:\n",
    "            if row[field] == \"NULL\" or row[field] == \"\":\n",
    "                fieldtypes[field].append(type(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': {<class 'NoneType'>, <class 'list'>}, 'timeZone_label': {<class 'NoneType'>}, 'utcOffset': {<class 'float'>, <class 'NoneType'>, <class 'list'>}, 'homepage': {<class 'NoneType'>}, 'governmentType_label': {<class 'NoneType'>}, 'isPartOf_label': {<class 'NoneType'>, <class 'list'>}, 'areaCode': {<class 'NoneType'>, <class 'float'>}, 'populationTotal': {<class 'NoneType'>, <class 'float'>}, 'elevation': {<class 'NoneType'>, <class 'list'>}, 'maximumElevation': {<class 'NoneType'>}, 'minimumElevation': {<class 'NoneType'>}, 'populationDensity': {<class 'NoneType'>, <class 'list'>}, 'wgs84_pos#lat': set(), 'wgs84_pos#long': set(), 'areaLand': {<class 'NoneType'>, <class 'list'>}, 'areaMetro': {<class 'NoneType'>}, 'areaUrban': {<class 'NoneType'>}}\n"
     ]
    }
   ],
   "source": [
    "fieldtypes = {}\n",
    "for i in FIELDS:\n",
    "    fieldtypes[i] = []\n",
    "with open(CITIES,'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    header = reader.fieldnames\n",
    "    for field in FIELDS:\n",
    "        for row in reader:\n",
    "            if row[field] == \"NULL\" or row[field] == \"\":\n",
    "                fieldtypes[field].append(type(None))\n",
    "            elif row[field][0] == '{':\n",
    "                fieldtypes[field].append(type([]))\n",
    "            elif isint(row[field]):\n",
    "                    fieldtypes[field].append(type(1.1))\n",
    "        f.seek(0)\n",
    "for i in fieldtypes:\n",
    "    fieldtypes[i] = set(fieldtypes[i])\n",
    "print(fieldtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
