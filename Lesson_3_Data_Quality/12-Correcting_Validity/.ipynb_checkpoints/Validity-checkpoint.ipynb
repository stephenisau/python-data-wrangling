{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "The following things should be done:\n",
    "- check if the field \"productionStartYear\" contains a year\n",
    "- check if the year is in range 1886-2014\n",
    "- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in range, as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "\n",
    "You can write helper functions for checking the data and writing the files, but we will call only the \n",
    "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
    "\"\"\"\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "INPUT_FILE = 'autos.csv'\n",
    "OUTPUT_GOOD = 'autos-valid.csv'\n",
    "OUTPUT_BAD = 'FIXME-autos.csv'\n",
    "\n",
    "def process_file(input_file, output_good, output_bad):\n",
    "\n",
    "\n",
    "        good_data = []\n",
    "        bad_data = []\n",
    "        with open(inpute_file,'r') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            header = reader.fieldnames#stores fieldnames into header\n",
    "            for row in reader:\n",
    "                if row['URI'].find(\"dbpedia.org\") < 0:\n",
    "                #if \"dbpedia.org\" in row[\"URI\"] also works\n",
    "                    continue\n",
    "                ps_year = row['productionStartYear'][:4]\n",
    "                #The format for the dates in the rows have\n",
    "                #year as the first 4 characters in the string.\n",
    "                #This line of code takes advantage of this fact\n",
    "                try:\n",
    "                    #this will replace the strings of data in the row with the truncated year string\n",
    "                    ps_year = int(ps_year)\n",
    "                    if (ps_year >= 1886) and (ps_year <= 2014):\n",
    "                        good_data.append(row)#if it falls in the range, append to good list\n",
    "                    else:\n",
    "                        bad_data.append(row)\n",
    "                except ValueError:#this exception encodes for the Null values\n",
    "                    if ps_year == \"NULL\":\n",
    "                        bad_data.append(row)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # This is just an example on how you can use csv.DictWriter\n",
    "    # Remember that you have to output 2 files\n",
    "    with open(output_good, \"w\") as g:\n",
    "        writer = csv.DictWriter(g, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in YOURDATA:\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is code I used to test out various parts of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['URI', 'rdf-schema#label', 'rdf-schema#comment', 'assembly_label', 'assembly', 'automobilePlatform_label', 'automobilePlatform', 'bodyStyle_label', 'bodyStyle', 'class_label', 'class', 'designCompany_label', 'designCompany', 'designer_label', 'designer', 'engine_label', 'engine', 'fuelCapacity', 'height', 'layout_label', 'layout', 'length', 'manufacturer_label', 'manufacturer', 'modelEndYear', 'modelStartYear', 'parentCompany_label', 'parentCompany', 'predecessor_label', 'predecessor', 'productionEndDate', 'productionEndYear', 'productionStartDate', 'productionStartYear', 'relatedMeanOfTransportation_label', 'relatedMeanOfTransportation', 'sales_label', 'sales', 'successor_label', 'successor', 'thumbnail_label', 'thumbnail', 'transmission', 'variantOf_label', 'variantOf', 'vehicle_label', 'vehicle', 'weight', 'wheelbase', 'width', 'point', '22-rdf-syntax-ns#type_label', '22-rdf-syntax-ns#type', 'wgs84_pos#lat', 'wgs84_pos#long', 'depiction_label', 'depiction', 'name']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pprint\n",
    "\n",
    "INPUT_FILE = 'autos.csv'\n",
    "OUTPUT_GOOD = 'autos-valid.csv'\n",
    "OUTPUT_BAD = 'FIXME-autos.csv'\n",
    "\n",
    "good_data = []#empty dictionary of good data values\n",
    "bad_data = []#empty dictionary of bad data values\n",
    "with open(INPUT_FILE,'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    header = reader.fieldnames\n",
    "    print(header)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dbpedia.org/resource/Mazda_MX-5\n",
      "http://dbpedia.org/resource/Nissan_Z-car\n",
      "http://dbpedia.org/resource/Lotus_Seven\n",
      "http://dbpedia.org/resource/Chaika_(car)\n",
      "http://dbpedia.org/resource/Lada_Samara\n",
      "http://dbpedia.org/resource/BMW_328\n",
      "http://dbpedia.org/resource/Green_Goddess\n",
      "http://dbpedia.org/resource/Porsche_Cayenne\n",
      "http://dbpedia.org/resource/Pontiac_Vibe\n",
      "http://dbpedia.org/resource/Ford_Taurus\n",
      "http://dbpedia.org/resource/Ford_Anglia\n",
      "http://dbpedia.org/resource/Toyota_Celica\n",
      "http://dbpedia.org/resource/Vespa_400\n",
      "http://dbpedia.org/resource/Edsel\n",
      "http://dbpedia.org/resource/Reliant_Fox\n",
      "http://dbpedia.org/resource/Ford_Cortina\n",
      "http://dbpedia.org/resource/Pontiac_GTO\n",
      "http://dbpedia.org/resource/Vauxhall_Viva\n",
      "http://dbpedia.org/resource/Reliant_Scimitar\n",
      "http://dbpedia.org/resource/Vauxhall_Astra\n",
      "http://dbpedia.org/resource/AC_Cobra\n",
      "http://dbpedia.org/resource/Volvo_66\n",
      "http://dbpedia.org/resource/Volvo_Duett\n",
      "http://dbpedia.org/resource/Saab_9-2\n",
      "http://dbpedia.org/resource/Saab_900\n",
      "http://dbpedia.org/resource/Chalmers_Automobile\n",
      "http://dbpedia.org/resource/Chevrolet_Impala\n",
      "http://dbpedia.org/resource/Ford_Crown_Victoria\n",
      "http://dbpedia.org/resource/BMW_Dixi\n",
      "http://dbpedia.org/resource/Toyota_Land_Cruiser\n",
      "http://dbpedia.org/resource/Volkswagen_Jetta\n",
      "http://dbpedia.org/resource/E-M-F_Company\n",
      "http://dbpedia.org/resource/Ford_Thunderbird\n",
      "http://dbpedia.org/resource/Toyota_Matrix\n",
      "http://dbpedia.org/resource/Honda_Integra\n",
      "http://dbpedia.org/resource/Plymouth_Road_Runner\n",
      "http://dbpedia.org/resource/Lancia_Delta\n",
      "http://dbpedia.org/resource/AMC_Pacer\n",
      "http://dbpedia.org/resource/Ford_Windstar\n",
      "http://dbpedia.org/resource/Ford_Parklane\n",
      "http://dbpedia.org/resource/Ford_Torino\n",
      "http://dbpedia.org/resource/Nissan_Maxima\n",
      "http://dbpedia.org/resource/Dodge_Caravan\n",
      "http://dbpedia.org/resource/Chevrolet_Avalanche\n",
      "http://dbpedia.org/resource/Saab_95\n",
      "http://dbpedia.org/resource/Volvo_P1900\n"
     ]
    }
   ],
   "source": [
    "with open(INPUT_FILE,'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    header = reader.fieldnames\n",
    "    for row in reader:\n",
    "        if \"dbpedia.org\" in row[\"URI\"]:\n",
    "            print(row[\"URI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dbpedia.org/ontology/productionStartYear\n",
      "XMLSchema#gYear\n",
      "http://www.w3.org/2001/XMLSchema#gYear\n",
      "1989-01-01T00:00:00+02:00\n",
      "1969-01-01T00:00:00+02:00\n",
      "1957-01-01T00:00:00+02:00\n",
      "1959-01-01T00:00:00+02:00\n",
      "2108-01-01T00:00:00+02:00\n",
      "1936-01-01T00:00:00+02:00\n",
      "1953-01-01T00:00:00+02:00\n",
      "2002-01-01T00:00:00+02:00\n",
      "2002-01-01T00:00:00+02:00\n",
      "1985-01-01T00:00:00+02:00\n",
      "1939-01-01T00:00:00+02:00\n",
      "1970-01-01T00:00:00+02:00\n",
      "1957-01-01T00:00:00+02:00\n",
      "1958-01-01T00:00:00+02:00\n",
      "1983-01-01T00:00:00+02:00\n",
      "1962-01-01T00:00:00+02:00\n",
      "1964-01-01T00:00:00+02:00\n",
      "0001-01-01T00:00:00+02:00\n",
      "1964-01-01T00:00:00+02:00\n",
      "1979-01-01T00:00:00+02:00\n",
      "1961-01-01T00:00:00+02:00\n",
      "1975-01-01T00:00:00+02:00\n",
      "1953-01-01T00:00:00+02:00\n",
      "NULL\n",
      "1978-01-01T00:00:00+02:00\n",
      "1908-01-01T00:00:00+02:00\n",
      "1994-01-01T00:00:00+02:00\n",
      "1955-01-01T00:00:00+02:00\n",
      "1927-01-01T00:00:00+02:00\n",
      "1951-01-01T00:00:00+02:00\n",
      "1979-01-01T00:00:00+02:00\n",
      "NULL\n",
      "1955-01-01T00:00:00+02:00\n",
      "2002-01-01T00:00:00+02:00\n",
      "1985-01-01T00:00:00+02:00\n",
      "1968-01-01T00:00:00+02:00\n",
      "1979-01-01T00:00:00+02:00\n",
      "1975-01-01T00:00:00+02:00\n",
      "1994-01-01T00:00:00+02:00\n",
      "1956-01-01T00:00:00+02:00\n",
      "1968-01-01T00:00:00+02:00\n",
      "1977-01-01T00:00:00+02:00\n",
      "1983-01-01T00:00:00+02:00\n",
      "2001-01-01T00:00:00+02:00\n",
      "1959-01-01T00:00:00+02:00\n",
      "1956-01-01T00:00:00+02:00\n"
     ]
    }
   ],
   "source": [
    "with open(INPUT_FILE,'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    header = reader.fieldnames\n",
    "    for row in reader:\n",
    "        print(row[\"productionStartYear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'NULL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b5a3153818a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mps_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'productionStartYear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mps_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1886\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mps_year\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2014\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'NULL'"
     ]
    }
   ],
   "source": [
    "with open(INPUT_FILE,'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    header = reader.fieldnames\n",
    "    for row in reader:\n",
    "        if row['URI'].find(\"dbpedia.org\") < 0:\n",
    "                #if \"dbpedia.org\" in row[\"URI\"] also works\n",
    "            continue\n",
    "        ps_year = row['productionStartYear'][:4]\n",
    "        ps_year = int(ps_year)\n",
    "        print(1886 <= ps_year <= 2014)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
